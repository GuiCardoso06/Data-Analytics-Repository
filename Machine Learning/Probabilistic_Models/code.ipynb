{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Parte 1**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **DataSet**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"imdb_movies.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Tratamento de Dados**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Valores em Falta e Escolha de Variáveis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.info() #2 colunas com valores em falta ('genre' e 'crew' )\n",
    "\n",
    "df['genre'].fillna('Unknown', inplace=True) #para não remover esses filmes, cria-se um género 'Desconhecido'\n",
    "\n",
    "df.drop('crew', axis=1, inplace=True) \n",
    "df.drop('overview', axis=1, inplace=True) \n",
    "df.drop('orig_title', axis=1, inplace=True) \n",
    "\n",
    "df.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Análise Exploratória de Dados**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Estastísticas Descritivas**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualização de Dados**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Score\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.hist(df['score'], bins=20, color='blue', alpha=0.7)\n",
    "plt.title('Distribuição da Pontuação dos Filmes')\n",
    "plt.xlabel('Pontuação')\n",
    "plt.ylabel('Frequência')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "#Orçamento\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.hist(df['budget_x'], bins=20, color='green', alpha=0.7)\n",
    "plt.title('Distribuição do Orçamento dos Filmes')\n",
    "plt.xlabel('Orçamento')\n",
    "plt.ylabel('Frequência')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "#Receita \n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.hist(df['revenue'], bins=20, color='red', alpha=0.7)\n",
    "plt.title('Distribuição da Receita dos Filmes')\n",
    "plt.xlabel('Receita')\n",
    "plt.ylabel('Frequência')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Identificar Outliers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Score\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.boxplot(df['score'], vert=False)\n",
    "plt.title('Box Plot da Pontuação dos Filmes')\n",
    "plt.xlabel('Pontuação')\n",
    "plt.show()\n",
    "\n",
    "#Orçamento\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.boxplot(df['budget_x'], vert=False)\n",
    "plt.title('Box Plot do Orçamento dos Filmes')\n",
    "plt.xlabel('Orçamento')\n",
    "plt.show()\n",
    "\n",
    "#Receita\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.boxplot(df['revenue'], vert=False)\n",
    "plt.title('Box Plot da Receita dos Filmes')\n",
    "plt.xlabel('Receita')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Análise de Correlação**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "#converter variáveis categóricas para códigos numéricos\n",
    "categorical_vars = ['genre', 'status', 'orig_lang', 'country']\n",
    "for var in categorical_vars:\n",
    "    df[var] = pd.Categorical(df[var]).codes\n",
    "\n",
    "#transformar datas \n",
    "if df['date_x'].dtype == 'object':\n",
    "    df['date_x'] = pd.to_datetime(df['date_x']).dt.strftime('%Y%m%d').astype(int)\n",
    "\n",
    "val_matrix = df[['date_x', 'score', 'genre', 'status', 'orig_lang', 'budget_x', 'revenue', 'country']]\n",
    "\n",
    "#matriz de correlação\n",
    "correlation_matrix = val_matrix.corr()\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "plt.title('Matriz de Correlação entre as Variáveis Selecionadas')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Rede Bayesiana**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Construção e Visualização do Modelo/Rede**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pgmpy.models import BayesianNetwork\n",
    "from pgmpy.factors.discrete import TabularCPD\n",
    "import networkx as nx\n",
    "\n",
    "#definir estrutura da rede\n",
    "model = BayesianNetwork([\n",
    "    ('budget_x', 'revenue'),\n",
    "    ('budget_x', 'date_x'),\n",
    "    ('status', 'score'),\n",
    "    ('country', 'revenue'),\n",
    "    ('orig_lang', 'revenue'),\n",
    "    ('budget_x', 'orig_lang'),\n",
    "    ('country', 'genre')\n",
    "])\n",
    "\n",
    "#CPD para 'budget_x' (Assumindo 3 categorias de orçamento: baixo, médio, alto)\n",
    "cpd_budget_x = TabularCPD(variable='budget_x', variable_card=3,\n",
    "                          values=[[0.3], [0.4], [0.3]])\n",
    "\n",
    "#CPD para 'revenue' dependente de 'budget_x', 'orig_lang' e 'country'\n",
    "cpd_revenue = TabularCPD(variable='revenue', variable_card=3,\n",
    "                         values=[[0.1, 0.2, 0.3, 0.2, 0.3, 0.4, 0.2, 0.3, 0.4, 0.1, 0.2, 0.3, 0.2, 0.3, 0.4, 0.2, 0.3, 0.4],\n",
    "                                 [0.3, 0.2, 0.1, 0.4, 0.2, 0.1, 0.4, 0.2, 0.1, 0.3, 0.2, 0.1, 0.4, 0.2, 0.1, 0.4, 0.2, 0.1],\n",
    "                                 [0.6, 0.6, 0.6, 0.4, 0.5, 0.5, 0.4, 0.5, 0.5, 0.6, 0.6, 0.6, 0.4, 0.5, 0.5, 0.4, 0.5, 0.5]],\n",
    "                         evidence=['budget_x', 'orig_lang', 'country'],\n",
    "                         evidence_card=[3, 2, 3])\n",
    "\n",
    "#CPD para 'date_x' dependente de 'budget_x'\n",
    "cpd_date_x = TabularCPD(variable='date_x', variable_card=3,\n",
    "                        values=[[0.4, 0.2, 0.1],\n",
    "                                [0.3, 0.5, 0.3],\n",
    "                                [0.3, 0.3, 0.6]],\n",
    "                        evidence=['budget_x'],\n",
    "                        evidence_card=[3])\n",
    "\n",
    "#CPD para 'score' dependente de 'status'\n",
    "cpd_score = TabularCPD(variable='score', variable_card=3,\n",
    "                       values=[[0.5, 0.3, 0.2],\n",
    "                               [0.2, 0.5, 0.3],\n",
    "                               [0.3, 0.2, 0.5]],\n",
    "                       evidence=['status'],\n",
    "                       evidence_card=[3])\n",
    "\n",
    "cpd_genre = TabularCPD(variable='genre', variable_card=3,\n",
    "                       values=[[0.5, 0.2, 0.3],\n",
    "                               [0.3, 0.5, 0.2],\n",
    "                               [0.2, 0.3, 0.5]],\n",
    "                       evidence=['country'],\n",
    "                       evidence_card=[3])\n",
    "\n",
    "#CPD para 'status' (Assumindo 3 estados: em desenvolvimento, lançado, cancelado)\n",
    "cpd_status = TabularCPD(variable='status', variable_card=3,\n",
    "                        values=[[0.2], [0.7], [0.1]])\n",
    "\n",
    "#CPD para 'orig_lang' dependente de 'budget_x'\n",
    "cpd_orig_lang = TabularCPD(variable='orig_lang', variable_card=2,\n",
    "                           values=[[0.7, 0.3, 0.1],\n",
    "                                   [0.3, 0.7, 0.9]],\n",
    "                           evidence=['budget_x'],\n",
    "                           evidence_card=[3])\n",
    "\n",
    "#CPD para 'country' (Assumindo independência)\n",
    "cpd_country = TabularCPD(variable='country', variable_card=3,\n",
    "                         values=[[0.4], [0.4], [0.2]])\n",
    "\n",
    "model.add_cpds(cpd_budget_x, cpd_revenue, cpd_date_x, cpd_score, cpd_status, cpd_orig_lang, cpd_country, cpd_genre)\n",
    "\n",
    "#verificar modelo\n",
    "print(\"Model:\", model.check_model())\n",
    "\n",
    "#criar grafo através do modelo\n",
    "G = nx.DiGraph()\n",
    "G.add_edges_from(model.edges())\n",
    "\n",
    "#posições\n",
    "pos = {\n",
    "    'budget_x': (1, 1),\n",
    "    'revenue': (2, 2),\n",
    "    'date_x': (0, 0),\n",
    "    'status': (-1, 2),\n",
    "    'score': (-2, 1),\n",
    "    'country': (3, 1),\n",
    "    'orig_lang': (2, 1),\n",
    "    'genre' : (4,0)\n",
    "}\n",
    "\n",
    "nx.draw(G, pos, with_labels=True, node_size=2000, node_color='lightblue', font_size=12, arrowstyle='-|>', arrowsize=20)\n",
    "plt.title('Rede Bayesiana das Relações do Filme')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Inferências Condicionais**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pgmpy.inference import VariableElimination\n",
    "\n",
    "infer = VariableElimination(model)\n",
    "\n",
    "#probabilidade de 'revenue' dado que 'budget_x' é médio\n",
    "result = infer.query(variables=['revenue'], evidence={'budget_x': 1})\n",
    "\n",
    "#múltiplas evidências\n",
    "result_multi_evidence = infer.query(variables=['revenue'], evidence={'budget_x': 2, 'orig_lang': 0, 'country': 2})\n",
    "\n",
    "print(result_multi_evidence)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inferência com variação nas condições de orçamento\n",
    "for budget in range(3):  #0 = baixo, 1 = médio, 2 = alto\n",
    "    for country in range(3):  # assumindo três países diferentes\n",
    "        result = infer.query(variables=['revenue'], evidence={'budget_x': budget, 'country': country})\n",
    "        print(f\"Orçamento: {budget}, País: {country}, Distribuição de Receita: {result}\")\n",
    "\n",
    "#Impacto do status do filme na pontuação\n",
    "for status in range(3):  #0 = em desenvolvimento, 1 = lançado, 2 = cancelado\n",
    "    result = infer.query(variables=['score'], evidence={'status': status})\n",
    "    print(f\"Status: {status}, Distribuição de Pontuação: {result}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Parte 2**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Redução dos Posters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Script to resize images in a directory.\n",
    "IMPORTANT NOTE: it was executed locally in vscode, not here.\n",
    "\"\"\"\n",
    "\n",
    "from PIL import Image\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def resize_images(source_directory, target_directory, target_size=(128, 128)):\n",
    "    for filename in os.listdir(source_directory):\n",
    "      if filename.endswith('.jpg'):\n",
    "        try:\n",
    "          #Load the image\n",
    "          image_path = os.path.join(source_directory, filename)\n",
    "          image = Image.open(image_path)\n",
    "          # Resize the image\n",
    "          resized_img = image.resize(target_size)\n",
    "          # Save the resized image in a new directory\n",
    "          save_path = os.path.join(target_directory, filename)\n",
    "          # Save the resized image\n",
    "          resized_img.save(save_path)\n",
    "          print(f\"Resized {filename} to {target_size}, saved in {target_directory}\")\n",
    "        except Exception as e:\n",
    "            print(f'Corrupted image. Failed to resize {filename}: {e}')\n",
    "\n",
    "# source_image_directory = 'archive/covers'\n",
    "# target_image_directory = 'archive2/resized_covers'\n",
    "\n",
    "# Resize images to the directory to (128,128)\n",
    "# resize_images(source_image_directory, target_image_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Merge dos DataSet**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pré-Processamento de Dados**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ratings = pd.read_csv('ratings.csv')\n",
    "df_movies = pd.read_csv(\"movies.csv\")\n",
    "\n",
    "df_high_rating = df_ratings[df_ratings['rating'] >= 4] #só rating supeior a 4\n",
    "#df_generos = df_movies[df_movies['genres'].isin(['Comedy', 'Romance'])] #só comédias ou romances\n",
    "\n",
    "df_merge = pd.merge(df_movies, df_high_rating, on='movieId') #merge com o movieID\n",
    "df_main = df_merge.drop_duplicates(subset='movieId', keep='first') #remover duplicados\n",
    "\n",
    "#df_main.info()\n",
    "#df_main.set_index('movieId', inplace=True) #'movieId' como o índice do DataFrame\n",
    "df_main.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Redimensionamento das Imagens**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "image_folder = '/Users/guilhermecardoso/Desktop/Universidade/3 Ano/2 Semestre/Aprendizagem Probabilística e Reconhecimento de Padrões/Projeto/archive2/resized_covers'\n",
    "\n",
    "desired_size = (128, 128) \n",
    "\n",
    "def resize_image(image_path):\n",
    "    try:\n",
    "        with Image.open(image_path) as img:\n",
    "            resized_img = img.resize(desired_size)\n",
    "            return resized_img\n",
    "    except FileNotFoundError:\n",
    "        return None\n",
    "\n",
    "df_main['image_path'] = df_main['movieId'].apply(lambda x: os.path.join(image_folder, f\"{x:07d}.jpg\"))\n",
    "\n",
    "#Aplicar a função para redimensionar as imagens e armazenar numa nova coluna, 'image_path'\n",
    "df_main['resized_image'] = df_main['image_path'].apply(resize_image)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remover Filmes Sem Imagem**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main = df_main.dropna(subset=['resized_image'])\n",
    "#df_main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Verificar Imagem**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "specific_movie_id = 235  #exemplo\n",
    "\n",
    "image_row = df_main[df_main['movieId'] == specific_movie_id]\n",
    "\n",
    "if not image_row.empty and image_row.iloc[0]['resized_image'] is not None:\n",
    "    plt.imshow(image_row.iloc[0]['resized_image'])\n",
    "    plt.title(f\"Imagem Redimensionada para movieId {specific_movie_id}\")\n",
    "    plt.axis('off') \n",
    "    plt.show()\n",
    "else:\n",
    "    print(f\"Nenhuma imagem processada disponível para movieId {specific_movie_id}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Normalização dos Píxeis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "#Converter imagens para RGB e normalizar os pixels\n",
    "def normalize_image(img):\n",
    "    if img.mode != 'RGB':\n",
    "        img = img.convert('RGB')\n",
    "    img_array = np.array(img)\n",
    "    normalized_img = img_array / 255.0  #valores entre 0 e 1\n",
    "    return normalized_img\n",
    "\n",
    "df_main['normalized_image'] = df_main['resized_image'].apply(normalize_image)\n",
    "\n",
    "if len(set(df_main['normalized_image'].apply(lambda x: x.shape).unique())) > 1:\n",
    "    print(\"Existem imagens de tamanhos diferentes.\")\n",
    "else:\n",
    "    print(\"Todas as imagens estão padronizadas em tamanho e formato.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preparação dos Dados**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_main['normalized_image'] = df_main['normalized_image'].apply(lambda img: np.array(img) if not isinstance(img, np.ndarray) else img)\n",
    "images_array = np.stack(df_main['normalized_image'].values)\n",
    "\n",
    "X_train, X_test = train_test_split(images_array, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Dimensões do Conjunto de Treinamento:\", X_train.shape)\n",
    "print(\"Dimensões do Conjunto de Teste:\", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Modelo VAE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Dense, Lambda, Flatten, Reshape, Conv2D, Conv2DTranspose\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "def sampling(args):\n",
    "    z_mean, z_log_var = args #média e logaritmo da variância da distribuição latente\n",
    "    batch = K.shape(z_mean)[0]\n",
    "    dim = K.int_shape(z_mean)[1]\n",
    "    epsilon = K.random_normal(shape=(batch, dim))\n",
    "    return z_mean + K.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "input_shape = (128, 128, 3) \n",
    "latent_dim = 32  \n",
    "\n",
    "inputs = Input(shape=input_shape, name='encoder_input')\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(inputs) #primeira camada\n",
    "x = Conv2D(64, (3, 3), activation='relu', strides=(2, 2), padding='same')(x) #segunda camada , stride de 2x2 que diminui a dimensao da imagem pela metade\n",
    "x = Flatten()(x) #transforma em vetor\n",
    "z_mean = Dense(latent_dim, name='z_mean')(x) \n",
    "z_log_var = Dense(latent_dim, name='z_log_var')(x)\n",
    "z = Lambda(sampling, output_shape=(latent_dim,), name='z')([z_mean, z_log_var])\n",
    "encoder = Model(inputs, [z_mean, z_log_var, z], name='encoder')\n",
    "\n",
    "latent_inputs = Input(shape=(latent_dim,), name='z_sampling')\n",
    "x = Dense(64 * 64, activation='relu')(latent_inputs)\n",
    "x = Reshape((64, 64, 1))(x)  #64x64 com um canal\n",
    "x = Conv2DTranspose(64, (3, 3), activation='relu', strides=(2, 2), padding='same')(x) #dobra a dimensao\n",
    "x = Conv2DTranspose(32, (3, 3), activation='relu', padding='same')(x)\n",
    "outputs = Conv2D(3, (3, 3), activation='sigmoid', padding='same')(x) #ativação sigmoide para normalizar a saída na faixa [0, 1]\n",
    "decoder = Model(latent_inputs, outputs, name='decoder')\n",
    "\n",
    "class VAE(Model):\n",
    "    def __init__(self, encoder, decoder, **kwargs):\n",
    "        super(VAE, self).__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        z_mean, z_log_var, z = self.encoder(inputs)\n",
    "        reconstructed = self.decoder(z)\n",
    "        reconstruction_loss = K.mean(K.square(inputs - reconstructed)) #calcula a perda de reconstrução como a média do erro quadrático entre a entrada e a saída reconstruída\n",
    "        reconstruction_loss *= input_shape[0] * input_shape[1] #calcula a perda de divergência KL (Kullback-Leibler) entre a distribuição latente aproximada e a distribuição normal padrão.\n",
    "        kl_loss = -0.5 * K.sum(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1)\n",
    "        total_loss = K.mean(reconstruction_loss + kl_loss)\n",
    "        self.add_loss(total_loss)\n",
    "        return reconstructed\n",
    "\n",
    "vae = VAE(encoder, decoder)\n",
    "vae.compile(optimizer='adam')\n",
    "\n",
    "\n",
    "history = vae.fit(X_train, epochs=100, batch_size=32, validation_split=0.2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_images = X_test[:10]  \n",
    "reconstructed_images = vae.predict(test_images)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(2, 10, figsize=(20, 4))\n",
    "for i in range(10):\n",
    "    ax = axes[0, i]\n",
    "    ax.imshow(test_images[i], cmap='gray')\n",
    "    ax.axis('off')\n",
    "    ax.set_title(\"Original\")\n",
    "\n",
    "    ax = axes[1, i]\n",
    "    ax.imshow(reconstructed_images[i], cmap='gray')\n",
    "    ax.axis('off')\n",
    "    ax.set_title(\"Reconstruída\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Modelo cVAE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from tensorflow.keras.layers import Input, Dense, Lambda, Flatten, Reshape, Concatenate, Conv2D, Conv2DTranspose\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "def load_and_process_images(image_folder, df_main, image_size=(128, 128)):\n",
    "    images = []\n",
    "    valid_genres = []\n",
    "    df_main['movieId'] = df_main['movieId'].fillna(0).astype(int)\n",
    "    for index, row in df_main.iterrows():\n",
    "        image_filename = f\"{row['movieId']:07d}.jpg\"\n",
    "        image_path = os.path.join(image_folder, image_filename)\n",
    "        if os.path.exists(image_path):\n",
    "            with Image.open(image_path) as img:\n",
    "                img = img.resize(image_size)\n",
    "                img = np.array(img)\n",
    "                if img.shape == (128, 128, 3):\n",
    "                    images.append(img)\n",
    "                    valid_genres.append(row['genres'].split('|') if isinstance(row['genres'], str) else ['Unknown'])\n",
    "    images = np.array(images) / 255.0\n",
    "    mlb = MultiLabelBinarizer()\n",
    "    genres_encoded = mlb.fit_transform(valid_genres) #transformar a lista de gêneros em um formato binarizado\n",
    "    return images, genres_encoded, mlb.classes_\n",
    "\n",
    "images, genres_encoded, genre_names = load_and_process_images(image_folder, df_main)\n",
    "images_train, images_test, genres_train, genres_test = train_test_split(images, genres_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "input_shape = (128, 128, 3)\n",
    "latent_dim = 32\n",
    "num_genres = len(genre_names)\n",
    "\n",
    "def sampling(args):\n",
    "    z_mean, z_log_var = args\n",
    "    epsilon = K.random_normal(shape=(K.shape(z_mean)[0], K.shape(z_mean)[1]))\n",
    "    return z_mean + K.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "inputs = Input(shape=input_shape)\n",
    "genre_inputs = Input(shape=(num_genres,))\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n",
    "x = Conv2D(64, (3, 3), activation='relu', strides=(2, 2), padding='same')(x)\n",
    "x = Flatten()(x)\n",
    "x = Concatenate()([x, genre_inputs]) #combinar a saida com os generos\n",
    "z_mean = Dense(latent_dim)(x)\n",
    "z_log_var = Dense(latent_dim)(x)\n",
    "z = Lambda(sampling)([z_mean, z_log_var])\n",
    "\n",
    "encoder = Model([inputs, genre_inputs], [z_mean, z_log_var, z])\n",
    "\n",
    "latent_inputs = Input(shape=(latent_dim,))\n",
    "decoder_input = Concatenate()([latent_inputs, genre_inputs])\n",
    "x = Dense(64 * 64, activation='relu')(decoder_input)\n",
    "x = Reshape((64, 64, 1))(x)\n",
    "x = Conv2DTranspose(64, (3, 3), activation='relu', strides=(2, 2), padding='same')(x)\n",
    "x = Conv2DTranspose(32, (3, 3), activation='relu', padding='same')(x)\n",
    "outputs = Conv2D(3, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "decoder = Model([latent_inputs, genre_inputs], outputs)\n",
    "\n",
    "class VAE(Model):\n",
    "    def __init__(self, encoder, decoder, **kwargs):\n",
    "        super(VAE, self).__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def call(self, inputs):\n",
    "        images, genres = inputs\n",
    "        z_mean, z_log_var, z = self.encoder([images, genres])\n",
    "        reconstructed = self.decoder([z, genres])\n",
    "        reconstruction_loss = K.mean(K.square(images - reconstructed)) #perda de reconstrução como a média do erro quadrático entre a entrada e a saída reconstruída\n",
    "        kl_loss = -0.5 * K.sum(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1) #perda de divergência KL\n",
    "        self.add_loss(K.mean(reconstruction_loss + kl_loss))\n",
    "        return reconstructed\n",
    "\n",
    "cvae = VAE(encoder, decoder)\n",
    "cvae.compile(optimizer=Adam(0.001))\n",
    "cvae.fit([images_train, genres_train], epochs=80, batch_size=32)\n",
    "\n",
    "action_vector = np.zeros((1, num_genres))\n",
    "action_index = np.where(genre_names == 'Action')[0][0]\n",
    "action_vector[0, action_index] = 1\n",
    "z_sample = np.random.normal(size=(1, latent_dim))\n",
    "generated_image = decoder.predict([z_sample, action_vector])\n",
    "\n",
    "plt.imshow(generated_image[0])\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
